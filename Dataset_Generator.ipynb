{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(image, annotations):\n",
    "    for annotation in annotations:\n",
    "        label, x_center, y_center, width, height = annotation\n",
    "        x_center *= image.shape[1]\n",
    "        y_center *= image.shape[0]\n",
    "        width *= image.shape[1]\n",
    "        height *= image.shape[0]\n",
    "        x_min = int(x_center - width / 2)\n",
    "        y_min = int(y_center - height / 2)\n",
    "        x_max = int(x_center + width / 2)\n",
    "        y_max = int(y_center + height / 2)\n",
    "        cv2.rectangle(image, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def horizontal_flip(image, annotations):\n",
    "    # Flip the image horizontally\n",
    "    flipped_image = cv2.flip(image, 1)\n",
    "\n",
    "    # Update bounding box coordinates\n",
    "    flipped_annotations = []\n",
    "    for annotation in annotations:\n",
    "        label, x, y, width, height = annotation\n",
    "        # Adjust the x-coordinate to reflect the horizontal flip\n",
    "        x = 1 - x\n",
    "        flipped_annotations.append((label, x, y, width, height))\n",
    "\n",
    "    return flipped_image, flipped_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vertical_flip(image, annotations):\n",
    "    # Flip the image vertically\n",
    "    flipped_image = cv2.flip(image, 0)\n",
    "\n",
    "    # Update bounding box coordinates\n",
    "    flipped_annotations = []\n",
    "    for annotation in annotations:\n",
    "        label, x_center, y_center, width, height = annotation\n",
    "        # Adjust the y-coordinate to reflect the vertical flip\n",
    "        y_center = 1 - y_center\n",
    "        flipped_annotations.append((label, x_center, y_center, width, height))\n",
    "    \n",
    "    return flipped_image, flipped_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_image(image):\n",
    "    scale = random.uniform(0.5, 1.5)  \n",
    "    # Get image dimensions\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # Perform the scaling\n",
    "    scaled_image = cv2.resize(image, (int(w*scale), int(h*scale)), interpolation = cv2.INTER_LINEAR)\n",
    "\n",
    "    return scaled_image, scale\n",
    "\n",
    "def scale_annotations(annotations, scale):\n",
    "    scaled_annotations = []\n",
    "    for annotation in annotations:\n",
    "        label, x_center, y_center, width, height = annotation\n",
    "        # Adjust the coordinates to reflect the scaling\n",
    "        x_center *= scale\n",
    "        y_center *= scale\n",
    "        width *= scale\n",
    "        height *= scale\n",
    "        scaled_annotations.append((label, x_center, y_center, width, height))\n",
    "\n",
    "    return scaled_annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_jitter(image, annotations):\n",
    "    # Randomly adjust brightness, contrast, saturation, and hue\n",
    "    alpha = np.random.uniform(0.5, 1.5)  # Adjust brightness (0.8 to 1.2)\n",
    "    beta = np.random.uniform(0.8, 1.2)   # Adjust contrast (0.8 to 1.2)\n",
    "    gamma = np.random.uniform(0.8, 1.2)  # Adjust saturation (0.8 to 1.2)\n",
    "    delta = np.random.uniform(-10, 10)   # Adjust hue (-10 to 10)\n",
    "\n",
    "    # Convert to HSV color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Adjust brightness\n",
    "    hsv_image[:, :, 2] = np.clip(alpha * hsv_image[:, :, 2], 0, 255)\n",
    "\n",
    "    # Adjust contrast\n",
    "    image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2BGR)\n",
    "    image = np.clip(beta * image, 0, 255).astype(np.uint8)\n",
    "\n",
    "    # Adjust saturation\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hsv_image[:, :, 1] = np.clip(gamma * hsv_image[:, :, 1], 0, 255)\n",
    "\n",
    "    # Adjust hue\n",
    "    hsv_image[:, :, 0] = (hsv_image[:, :, 0] + delta) % 180\n",
    "\n",
    "    image = cv2.cvtColor(hsv_image, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    return image, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_blur(image, annotations):\n",
    "    # Randomly select the blur kernel size\n",
    "    kernel_size = np.random.choice([25, 15, 19, 29])  # You can customize the kernel sizes\n",
    "\n",
    "    # Apply Gaussian blur to the image\n",
    "    blurred_image = cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)\n",
    "\n",
    "    return blurred_image, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_noise(image, annotations):\n",
    "    # Generate random Gaussian noise\n",
    "    noise = np.random.normal(0, 1, image.shape).astype(np.uint8)\n",
    "\n",
    "    # Add noise to the image\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "\n",
    "    return noisy_image, annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image(image, annotations):\n",
    "\n",
    "\n",
    "    \n",
    "    cropped_annotations = []\n",
    "    label, x_center, y_center, width, height = annotations[0]\n",
    "    y_start = random.uniform(0, y_center)\n",
    "    x_start = random.uniform(0, x_center)\n",
    "    x_end = random.uniform(x_center, 1)\n",
    "    y_end = random.uniform(y_center, 1)    \n",
    "    \n",
    "    cropped_image = image[int(y_start*image.shape[0]):int(y_end*image.shape[0]), int(x_start*image.shape[1]):int(x_end*image.shape[1])]\n",
    "    y_center = (y_center - y_start) / (y_end - y_start)\n",
    "    x_center = (x_center - x_start) / (x_end - x_start)\n",
    "    cropped_annotations.append((label, x_center, y_center, width, height))\n",
    "    return cropped_image, annotations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_transform(image, annotations):\n",
    "# Get the height and width of the image\n",
    "    height, width, _ = image.shape\n",
    "\n",
    "# Create a random color transformation matrix\n",
    "    random_color_matrix = np.random.rand(3, 3)/3  # A 3x3 matrix with random values between 0 and 1\n",
    "\n",
    "    transformed_image = np.dot(image.copy().reshape(-1, 3), random_color_matrix.T).reshape(height, width, 3)\n",
    "    transformed_image = np.clip(transformed_image, 0, 255).astype(np.uint8)  # Clip and convert to uint8\n",
    "\n",
    "\n",
    "    return transformed_image, annotations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate(image, annotations):\n",
    "    rotation_center = (image.shape[1] // 2, image.shape[0] // 2)  # Center of the image\n",
    "\n",
    "    # Define the rotation angle in degrees\n",
    "    rotation_angle = np.random.randint(0, 90)  # Replace with your desired rotation angle\n",
    "\n",
    "    # Calculate the rotation matrix\n",
    "    rotation_matrix = cv2.getRotationMatrix2D(rotation_center, rotation_angle, 1.0)\n",
    "\n",
    "    # Rotate the entire image\n",
    "    rotated_image = cv2.warpAffine(image, rotation_matrix, (image.shape[1], image.shape[0]))\n",
    "    rotated_annotations = []\n",
    "    for annotation in annotations:\n",
    "        label, x_center, y_center, width, height = annotation\n",
    "        x_center *= image.shape[1]\n",
    "        y_center *= image.shape[0]\n",
    "        width *= image.shape[1]\n",
    "        height *= image.shape[0]\n",
    "        if width>= height:\n",
    "            diagonal = width\n",
    "        else: diagonal = height\n",
    "        # diagonal = np.sqrt(height**2 + width**2)\n",
    "        point_to_locate = (x_center, y_center) \n",
    "\n",
    "        theta = np.rad2deg(np.arctan(height/width)) + rotation_angle\n",
    "        point_after_rotation = np.dot(rotation_matrix, np.array([point_to_locate[0], point_to_locate[1], 1]))\n",
    "        width_after_rotation = diagonal*np.abs(np.cos(np.deg2rad(theta)))/image.shape[1]\n",
    "        height_after_rotation = diagonal*np.abs(np.sin(np.deg2rad(theta)))/image.shape[0]\n",
    "        x_after_rotation = int(point_after_rotation[0])/image.shape[1]\n",
    "        y_after_rotation = int(point_after_rotation[1])/image.shape[0]\n",
    "        rotated_annotations.append((int(label), x_after_rotation, y_after_rotation, width_after_rotation, height_after_rotation))\n",
    "        print(rotated_annotations)\n",
    "    return rotated_image, rotated_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_comparison(image, annotations, sub_image, sub_annotations):\n",
    "    print(sub_annotations)            \n",
    "    draw_bounding_boxes(image, annotations)\n",
    "    draw_bounding_boxes(sub_image, sub_annotations)        \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Original Image\")\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(cv2.cvtColor(sub_image, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Transformed Image\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_transformation(image, annotations):\n",
    "    choices = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "\n",
    "# Define the probabilities for each integer\n",
    "    probabilities = np.array([0.135, 0.135, 0.135, 0.135, 0.135, 0.135, 0.135, 0.055])\n",
    "\n",
    "# Number of random integers to generate\n",
    "    num_samples = 4\n",
    "\n",
    "# Generate an array of random integers based on the specified probabilities\n",
    "    # order = np.random.choice(choices, size=num_samples, p=probabilities)\n",
    "    order = np.random.randint(1,9, 3)\n",
    "\n",
    "    print(order)\n",
    "    sub_image, sub_annotations = image, annotations\n",
    "    for i in order:\n",
    "        if i == 1:\n",
    "            print('h_flip')\n",
    "            sub_image, sub_annotations = horizontal_flip(\n",
    "                sub_image, sub_annotations)\n",
    "\n",
    "            # image_comparison(image, annotations, sub_image, sub_annotations)\n",
    "\n",
    "        elif i == 2:\n",
    "            print('v_flip')\n",
    "            sub_image, sub_annotations = vertical_flip(\n",
    "                sub_image, sub_annotations)\n",
    "\n",
    "            # image_comparison(image, annotations, sub_image, sub_annotations)\n",
    "\n",
    "        elif i == 3:\n",
    "            print('color_jitter')\n",
    "            sub_image, sub_annotations = color_jitter(\n",
    "                sub_image, sub_annotations)\n",
    "\n",
    "            # image_comparison(image, annotations, sub_image, sub_annotations)\n",
    "\n",
    "        elif i == 4:\n",
    "            print('apply_blur')\n",
    "            sub_image, sub_annotations = apply_blur(sub_image, sub_annotations)\n",
    "\n",
    "            # image_comparison(image, annotations, sub_image, sub_annotations)\n",
    "\n",
    "        elif i == 5:\n",
    "            print('noise')\n",
    "            sub_image, sub_annotations = apply_noise(\n",
    "                sub_image, sub_annotations)\n",
    "\n",
    "            # image_comparison(image, annotations, sub_image, sub_annotations)\n",
    "\n",
    "        elif i == 6:\n",
    "            print('scale')\n",
    "            sub_image, sub_scale = scale_image(sub_image)\n",
    "\n",
    "            # image_comparison(image, annotations, sub_image, sub_annotations)\n",
    "        elif i == 7:\n",
    "            print('color_transform')\n",
    "            sub_image, sub_annotations = color_transform(\n",
    "                sub_image, sub_annotations)\n",
    "        elif i == 8:\n",
    "            print('rotate')\n",
    "            sub_image, sub_annotations = rotate(sub_image, sub_annotations)\n",
    "        elif i==9:\n",
    "            print('crop')\n",
    "            sub_image, sub_annotations = crop_image(sub_image, sub_annotations)\n",
    "\n",
    "    image_comparison(image, annotations, sub_image, sub_annotations)\n",
    "    \n",
    "    return order, sub_image, sub_annotations\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_label_file(label_destination, original_name,annotations, i,dataset_size):\n",
    "    file_path = os.path.join(label_destination, f'{dataset_size+i+dataset_size}_{original_name}.txt')\n",
    "    with open(file_path, \"w\") as file:\n",
    "        for annotation in annotations:\n",
    "            content = \"\"\n",
    "            for i, item in enumerate(annotation):\n",
    "                if i == 0:\n",
    "                    content += str(int(item))  # Ensure the first item is an integer\n",
    "                else:\n",
    "                    content += str(float(item))  # Convert the rest to floats\n",
    "                if i < len(annotation) - 1:\n",
    "                    content += \" \" \n",
    "            file.write(content + \"\\n\")  \n",
    "    # File is automatically closed when the 'with' block exits\n",
    "    print(f\"Content has been written to {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_file(image_destination, original_name, image, i, dataset_size):\n",
    "    image_path = os.path.join(image_destination, f'{dataset_size+i+dataset_size}_{original_name}.jpg')\n",
    "    cv2.imwrite(image_path, image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_source = 'Initial_dataset\\images'\n",
    "label_source = 'Initial_dataset\\labels'\n",
    "\n",
    "image_destination  = 'transformed_dataset\\images'\n",
    "label_destination  = 'transformed_dataset\\labels'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(image_source, label_source, image_destination, label_destination, n):\n",
    "    \n",
    "    dataset_size = len(os.listdir(image_source))\n",
    "    for i in range(n):\n",
    "        if i>=dataset_size:\n",
    "            i = i-dataset_size\n",
    "        print(os.listdir(image_source))\n",
    "        image_name = os.listdir(image_source)[i]\n",
    "        image_path = os.path.join(image_source, image_name)\n",
    "        print(image_name, image_path)\n",
    "        image = cv2.imread(image_path)\n",
    "        label_path = os.path.join(label_source, os.path.splitext(image_name)[0]+'.txt')\n",
    "        print(label_path)\n",
    "        with open(label_path) as f:\n",
    "            annotations = [tuple(map(float, line.split())) for line in f]\n",
    "        order, image, annotations = apply_transformation(image, annotations)\n",
    "        create_image_file(image_destination, os.path.splitext(image_name)[0], image, i,dataset_size)\n",
    "        create_label_file(label_destination, os.path.splitext(image_name)[0], annotations, i,  dataset_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset(image_source, label_source, image_destination, label_destination, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
